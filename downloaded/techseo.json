[
  {
    "score": 203,
    "title": "I got frustrated with ScreamingFrog crawler pricing so I built an open-source alternative",
    "selftext": "I wasn't about to pay $259/year for Screaming Frog just to audit client websites. The free version caps at 500 URLs which is useless for any real site. I looked at alternatives like Sitebulb ($420/year) and DeepCrawl ($1000+/year) and thought \"this is ridiculous for what's essentially just crawling websites and parsing HTML.\"\n\nSo I built LibreCrawl over the past few months. It's MIT licensed and designed to run on your own infrastructure. It handles:\n\n* Technical SEO audits (broken links, missing meta tags, duplicate content, etc.)\n* JavaScript-heavy sites with Playwright rendering\n* 1M+ URLs with virtual scrolling and real-time memory profiling\n* Multi-tenant deployments for agencies\n* Unlimited exports (CSV/JSON/XML)\n\nIn its current state, it works and I use it daily for client audits. Documentation needs improvement and I'm sure there are bugs I haven't found yet. It's definitely rough around the edges compared to commercial tools but it does the core job.\n\nDemo: [https://librecrawl.com/app/](https://librecrawl.com/app/) (3 free crawls, no signup, install it on your own machine to get the full feature set, my server would die if i had everything enabled)  \nGitHub: [https://github.com/PhialsBasement/LibreCrawl](https://github.com/PhialsBasement/LibreCrawl)  \nPlugin Workshop: [https://librecrawl.com/workshop](https://librecrawl.com/workshop)\n\nHappy to answer technical questions or hear feedback on what's missing.",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.96,
    "subreddit_type": "public",
    "ups": 203,
    "downs": 0,
    "created_utc": 1763445623.0,
    "media": null,
    "is_video": false,
    "num_comments": 120,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 4.071022852584123
  },
  {
    "score": 68,
    "title": "ScamAdviser is damaging SEO for honest websites — here’s how",
    "selftext": "Just wanted to share a recent experience we had with a reputation management platform that negatively affected our SEO and visibility.\n\n**ScamAdviser, the scam pretending to fight scams**\n\nScamAdviser claims to fight online scams, but in reality, it’s one of the biggest frauds on the web.  \nHere’s how it works:\n\nThey destroy the reputation of new websites by making up fake fraud accusations out of thin air.  \nTo “fix” those lies, you’re asked to pay $14 for a so-called manual verification.  \nTheir platform is totally unmoderated — anyone can post anything about any website, no checks whatsoever.  \nThe result? A playground for trolls, fake reviewers, and shady competitors.\n\n**Real case: our website**\n\nWe found out by chance that ScamAdviser was rating our site as “60% scam risk”… supposedly because of “high-risk crypto services.”  \nExcept is 100% free.  \nNo cookies.  \nNo trackers.  \nNo ads.  \nNo payment systems whatsoever.\n\nIt takes less than 2 minutes to visit the site and see that ScamAdviser is completely lying.\n\n**But it gets worse.**\n\nAfter we sent them an email warning of a defamation lawsuit and saying we refused to pay their $14 scam, our score magically dropped to 95% scam risk.  \nAnd then — surprise! Dozens of fake profiles popped up claiming they had lost $100,000 on our site (again: it’s literally impossible to pay anything on our site).\n\nAnd guess what? Those same profiles post the exact same stories on tons of other sites.  \nSame copy-pasted text, same dollar amounts, same fake drama.\n\nCheck ScamAdviser’s Trustpilot page: you’ll see plenty of people reporting the exact same scam pattern.  \nHonest websites are being smeared, while known scam sites get great ratings — obviously, the ones that paid.\n\n**We dug a little deeper**\n\nTheir official address in Amsterdam is just a cheap rented mailbox.  \nTheir real activity has nothing to do with cybersecurity — it’s a fear-based manipulation business, dressed up as a \"trust tool.\"\n\n**What we’re doing now**\n\nWe’re inviting every webmaster out there to check what ScamAdviser says about their site — this can seriously tank your SEO.  \nIf they’re smearing your website like they did to ours, join our legal complaint and claim damages.  \nWe’re not just going after their fake company — we’re going after the individual responsible: **Jorij Abraham**.  \nWe’re also preparing an official GDPR complaint.  \nAnd any action that helps take this long-running scam down is more than welcome.\n\n**If you’re a victim of ScamAdviser, speak up. It’s time to shut this down.**",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.96,
    "subreddit_type": "public",
    "ups": 68,
    "downs": 0,
    "created_utc": 1746640165.0,
    "media": null,
    "is_video": false,
    "num_comments": 56,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 3.436786518573501
  },
  {
    "score": 63,
    "title": "I built an AI agent that watches indexing status, PageSpeed, and GSC—then emails a fix-plan",
    "selftext": "Hey folks—sharing a build that’s been super useful for me.\n\n**What it does:**\n\n* Fetches sitemap → logs URLs (Google Sheets)\n* Posts re-crawl pings where appropriate, then checks **URL Inspection API** for coverage\n* Pulls **Search Console Search Analytics** (queries, clicks, CTR, position)\n* Runs **PageSpeed Insights** for mobile &amp; desktop\n* Merges everything, then an AI step summarizes **what’s broken + what to do** (e.g., “preload hero image,” “reduce JS by X KB,” “internal links for these queries”)\n* Outputs a tidy HTML email\n\n**Why I built it:** tired of ad-hoc audits and missing indexing regressions.\n\n**Open questions / looking for feedback:**\n\n* Best way to prioritize issues across large sitemaps (weight by revenue? by query clicks?)\n* Favorite heuristics for “needs indexing vs. wait and watch”?\n* Anyone doing cost-based PageSpeed scoring (ms saved per KB vs. eng time)?\n\nHappy to share components or a sanitized workflow overview. If you want me to run it on a single URL and post anonymized results, drop a link (mods permitting). Not trying to hard-sell—mostly sharing the build and learning.",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.89,
    "subreddit_type": "public",
    "ups": 63,
    "downs": 0,
    "created_utc": 1756859821.0,
    "media": null,
    "is_video": false,
    "num_comments": 38,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 3.2692122774971364
  },
  {
    "score": 41,
    "title": "I wrote a 34-page-long free guide on technical SEO",
    "selftext": "Hi everyone,\n\nI'm a developer and, talking with other developers, I realized their knowledge on technical SEO (and SEO in general) is practically non existent.\n\nI'm not an expert myself, but I've been working on SEO for quite some time, and I've written more than 150 SEO-friendly blog articles for tech clients.\n\nSo I decided to share my knowledge in a free document.\n\nThe content will be very basic for some, but it can be helpful for people with zero knowledge in technical SEO, especially developers.\n\nI also mention programmatic SEO, and share a few links to learn more about it.\n\nHere is the guide, if you want to check it out: [https://www.seo-programming.com/technical\\_seo\\_guide.pdf](https://www.seo-programming.com/technical_seo_guide.pdf)",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.9,
    "subreddit_type": "public",
    "ups": 41,
    "downs": 0,
    "created_utc": 1721376580.0,
    "media": null,
    "is_video": false,
    "num_comments": 26,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 3.0139311724773945
  },
  {
    "score": 33,
    "title": "Things should never be automated in SEO",
    "selftext": "I have hired an intern to work with me to help with some SEO stuff here there. She is an awesome girl and picks up things very quickly, but I am having hard time explaining her that everything cannot be/should be automated in SEO.\n\nShe has done some coding in college and have good understanding how things work under the hood and now on a mission of automating almost everything.   \n  \nI would like to know your opinion on: what should be automated and what should never be automated in SEO?  \n  \nLet me know what you all have automated successfully and what you will never automate.\n\nFYI - This post has been shared with her already so she can read your comments directly.\n\nLong live SEO",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.88,
    "subreddit_type": "public",
    "ups": 33,
    "downs": 0,
    "created_utc": 1760468978.0,
    "media": null,
    "is_video": false,
    "num_comments": 29,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.9300395444020864
  },
  {
    "score": 30,
    "title": "Why the Disavow Tool still exists ",
    "selftext": "Google’s official position as expressed by John M. and repeated (parroted?) by the many “SEO influencers” on LinkedIn/Twitter-X/Reddit is that harmful backlinks cannot hurt your website because Google will simply ignore any backlinks it deems unnatural.\n\nLet’s examine this logic a bit, shall we?\n\nIf that’s indeed the case - that unnatural/harmful/toxic backlinks cannot hurt your website and should be simply ignored, then what’s the point of having the disavow tool at all? Seriously, why not just nuke it, Google? \n\n- Someone built a ton of PBN links to your site from a penalized PBN network - no problem, Google will simply ignore it.\n\n- Someone is building countless links and copy pasting your content on hacked websites with cloaked pages? No problem, Google will simply ignore everything even if that practice violates their quality guidelines.\n\n- Someone is buying backlinks to your site to implicate you/your website - no problem, Google has got your back!\n\nSo, if no amount and duration of unnatural backlinks can hurt you, then what’s the point of having the disavow tool?\n\nDoes the disavow tool even do anything? Why is it not a deprecated tool like the others?\n\nGoogle needs plausible deniability and wants webmasters/website owners to be confused and think that they may have the option to address harmful backlinks attacks against their websites (Google thinks it’s probably you who built those links in the first place in an attempt to game their search engine and they want you to think you might have an option to disavow them if you so choose). No, disavowing backlinks probably won’t help you.\n\nThe reality is that Google very much penalizes websites algorithmically for manipulating its search algo through unnatural backlinks, but does not want this advertised (keep it under the wraps) to avoid lawsuits and bad PR.\n\nCountless websites get demoted and relegated to obscurity for unnatural linking patters, PBN networks, hacked websites linking to you and using your content - the longer it goes on the greater the penalty effects over time. \n\nNo, unfortunately it’s not just pure speculation, there is plenty of hard data to unequivocally prove negative SEO is real and does real damage thanks to Google penalizing it algorithmically. I can share a detailed independent analysis and case studies spanning multiple cases over the last few years to prove this.\n\n\n\n\n\n\n\n\n",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.92,
    "subreddit_type": "public",
    "ups": 30,
    "downs": 0,
    "created_utc": 1717022930.0,
    "media": null,
    "is_video": false,
    "num_comments": 22,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.862225611843069
  },
  {
    "score": 28,
    "title": "Video is not the main content of the page (After doing everything to fix!)",
    "selftext": "https://preview.redd.it/76e3ceqprnoc1.png?width=2003&amp;format=png&amp;auto=webp&amp;s=58d0ca8ef03d2df7f6096d608e621903da373402\n\n  \nSo we have tried **everything** to fix the **'Video is not the main content of the page'** and it's still not working,video schema markup, video sitemaps, Separate URLs for the 'video pages' - 'Video' in slug etc.   \nThe specific GSC status for such video is:   \n\"Video placement: Video is supplementary content on the page\"  \n  \nIf there is a **skilled techseo** in here who has worked intensively on this issue, please reach out or chime in! :)  \n",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.98,
    "subreddit_type": "public",
    "ups": 28,
    "downs": 0,
    "created_utc": 1710577667.0,
    "media": null,
    "is_video": false,
    "num_comments": 37,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.987289796207361
  },
  {
    "score": 29,
    "title": "Ecommerce SEO Book - Advanced for Tech SEOs, Writers, Programmers",
    "selftext": "If you're interested, there is a free PDF download, no need to purchase - not looking for sales... still have some editing to do, but it is live on Amazon.  Not sure if I am allowed to post a link here, but PDF is available...\n\nI'd love feedback.  I plan to begin marketing it aggressively in June.  Your thoughts and recommendations would be great.  I've been working on it for 3 years and dedicated over the past 1.5 years.\n\n\nHere is the Free PDF of the book if you want to check it out [209 pgs PDF 6.4 MB](https://storiale.com/e-commerce-seo-book/sizzle-book-4-28-2023.pdf)  No you don't need to submit your email address, it is just a plain old download in PDF version.\n\nSome great things about the book, I've posted on here, but it is all about leveraging that data, adding variables, functions, a few algorithms that are being used by large e-commerce companies I've worked on, some paradigm-shifting info - the best link building for E-commerce, Better Information Architecture, and more.\n\nIf you go on Amazon and search Sizzle:  An Ecommerce Revolution - Advance E-commerce SEO it should come up.\n\n[link to amazon](https://www.amazon.com/Sizzle-Commerce-Revolution-commerce-Function-Driven/dp/B09YPGMFVM/ref=sr_1_1?crid=N7H6S4DT89WD&amp;keywords=storiale+ecommerce+seo&amp;qid=1652733157&amp;sprefix=storiale+ecommerce+seo+%2Caps%2C101&amp;sr=8-1)\n\nLou\n\nHere's my LinkedIn in case you want to check me out as legit.\n\nhttps://www.linkedin.com/in/storiale/",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.97,
    "subreddit_type": "public",
    "ups": 29,
    "downs": 0,
    "created_utc": 1680237619.0,
    "media": null,
    "is_video": false,
    "num_comments": 12,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.7615929308730807
  },
  {
    "score": 27,
    "title": "Does schema markup help SEO rankings or only rich results?",
    "selftext": "I see a lot of confusion around schema markup and SEO.\n\nSome say schema doesn’t directly affect rankings and only helps with rich results and CTR. Others claim they’ve seen ranking improvements after adding FAQ, Product, or Video schema.\n\nFrom a practical SEO perspective, does schema markup help with rankings at all, or is the value mainly indirect through SERP appearance and click-through rate?\n\nLooking for real-world experience, not theory.",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.94,
    "subreddit_type": "public",
    "ups": 27,
    "downs": 0,
    "created_utc": 1765278181.0,
    "media": null,
    "is_video": false,
    "num_comments": 31,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.904733020502172
  },
  {
    "score": 27,
    "title": "Is There a Future for SEO in an AI-Driven World?",
    "selftext": "People say the future of SEO is AEO and GEO—that we need to optimize for AI. But honestly, if in a few years AI becomes fully self-learning and can answer everything on its own, will link clicks even matter anymore? No one will bother visiting my website.\n\nBig tech companies could wipe out all links like Thanos if they wanted to, but it feels like they’re showing us a bit of mercy by leaving them around for now.\n\nSure, AI search is growing at a frightening pace, and its overall share is still relatively small. But as someone who genuinely loves my job—doing the kind of deeply human analysis that SEO requires—it still feels pretty bleak.",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.85,
    "subreddit_type": "public",
    "ups": 27,
    "downs": 0,
    "created_utc": 1763714527.0,
    "media": null,
    "is_video": false,
    "num_comments": 52,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.9467959661426137
  },
  {
    "score": 27,
    "title": "Need guidance on a tough SEO situation",
    "selftext": "Hi all,\n\nLast year, I hired a SEO specialist who worked with us for around 15 months. During that time, we created and published 50 blogs with the help of a content writer— but got zero traffic.\n\nThe strategy was to create 50 blogs and give it to Google in one shot. Since we had limited budget and small team, we created these 50 posts in 6 months time and submitted it to Google in Jan this year. This strategy was suggested by the SEO guy .\n\nWhile I understand that the nature of search is changing rapidly with AI, I honestly didn’t expect zero results.\n\nWhat’s been more frustrating is the lack of proactiveness at SEO guys end. While I raised concerns and gave him feedback, I still gave him 2 more months to improve things — but instead of progress, our indexed pages dropped from 42 to 14.\n\nNow I’m genuinely wondering if he is behind this decline.\n\nHas anyone experienced something similar? How do I assess what went wrong, and what should I do next?\n\nAny advice would be appreciated.\n\n",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.89,
    "subreddit_type": "public",
    "ups": 27,
    "downs": 0,
    "created_utc": 1749644868.0,
    "media": null,
    "is_video": false,
    "num_comments": 100,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 3.1168187182335405
  },
  {
    "score": 28,
    "title": "Python SEO tools + Repos",
    "selftext": "Hello, I wanted to share some of my open-source repos I have been working on for a while that are mainly for SEO and the consolidation of all of them into a new tool I have built for Keyword research, PAA, and Content recommendation ([kwrds.ai](https://www.kwrds.ai/)).\n\nI would love any feedback that you guys want to give me on the keyword research tool, and if you also want to contribute to the open-source repos I have, it would be great.\n\nKeyword research tool + PAA + AI --&gt; [https://www.kwrds.ai](https://www.kwrds.ai/)\n\nGreat for keyword research, and People Also ask questions. I have added AI to help go into more detailed keywords and answer questions. We have a good roadmap planned with many more features coming soon ( Filtering, People Also Search, Traffic estimations, Keyword difficulty and more). Any feedback would be amazing!\n\nFree Rank Checker --&gt; [https://github.com/sundios/Google-rank-tracker](https://github.com/sundios/Google-rank-tracker)\n\nThis is a great python rank tracker that you can automate to help you check your daily ranks and your competitor's rank. Built with BS4 and request. Ranks are checked on mobile and desktop\n\nPeople Also Ask --&gt; [https://github.com/sundios/people-also-ask](https://github.com/sundios/people-also-ask)\n\nThis script is part of my tool but gets people to ask questions directly into Google in different languages.\n\nSEO Checklist --&gt; [https://github.com/sundios/technical-seo-checklist](https://github.com/sundios/technical-seo-checklist)\n\nThis script does a check of important SEO things a site must have as of now, I have the following checks:\n\n* Mobile Friendly\n* Bot Accessibility\n* Indexation Status\n* Robots meta tag\n* X Robots tag\n* Canonicals\n* Schema\n* Core Web Vitals\n\nSEO visibility Score --&gt; [https://github.com/sundios/google-visibility-score](https://github.com/sundios/google-visibility-score)\n\nCalculate your visibility score using only google search console data. It's based on a keyword list and checking volumes and CTR.\n\nAny feedback on the tool or any contribution on the repos would be amazing! Also if anybody has any questions on how to start with python &amp; SEO DM me I would love to help.",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.95,
    "subreddit_type": "public",
    "ups": 28,
    "downs": 0,
    "created_utc": 1721446733.0,
    "media": null,
    "is_video": false,
    "num_comments": 11,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.7144886209227685
  },
  {
    "score": 26,
    "title": "Google Search Central confirms PageSpeed not as important as people think",
    "selftext": "About 30 seconds in Google says they will continue to show the best content regardless of CWV - this makes sense: Speed doesn't make content better or more accurate or less scammy or less spammy.\n\nBefore you jump to \"you can't trust Google\" - sorry but I'd rather trust Google over conjecture posted on a blog or podcast or some agency speaker at an SEO event. Also, people who say \"dont trust google\" also almost always quote pagespeed.\n\nI think PageSpeed has been overplayed as a Google Rank Signal for too long. Everytime someone has an issue ranking - 30% of people ask about pagespeed - I'm glad that in this instance we can help users with actual SEO ranking signals and ranking factors\n\n[https://www.youtube.com/watch?v=Ts7rPPIFhVg](https://www.youtube.com/watch?v=Ts7rPPIFhVg)\n\nWhat say you?",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.85,
    "subreddit_type": "public",
    "ups": 26,
    "downs": 0,
    "created_utc": 1726684701.0,
    "media": null,
    "is_video": false,
    "num_comments": 45,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.9002426799997743
  },
  {
    "score": 24,
    "title": "Schema and Layout Tweaks Shift AI Product Recommendations by 5x",
    "selftext": "Was looking into how AI agents decide which products to recommend, and there were a few patterns that seemed worth testing.\n\nBain &amp; Co. found that a large chunk of US consumers are already using generative AI to compare products, and close to 1 in 5 plan to start holiday shopping directly inside tools like ChatGPT or Perplexity.\n\nWhat interested me more though was a Columbia and Yale sandbox study that tested how AI agents make selections once they can confidently parse a webpage. They tried small tweaks to structure and content that made a surprisingly large difference:\n\n* Moving a product card into the top row increased its selection rate 5x\n* Adding an “Overall Pick” badge increased selection odds by more than 2x\n* Adding a “Sponsored” label reduced the chance of being picked, even when the product was identical\n* In some categories, a small number of items captured almost all AI driven picks while others were never selected at all\n\nWhat I understood from this is that AI agents behave much closer to ranking functions than mystery boxes. Once they parse the data cleanly, they respond to structure, placement, labeling, and attribute clarity in very measurable ways. If they can’t parse the data, it just never enters the candidate pool.\n\nHere are some starting points I thought were worth experimenting with:\n\n* Make sure core attributes (price, availability, rating, policies) are consistently exposed in clean markup\n* Check that schema isn’t partial or conflicting. A schema validator might say “valid” even if half the fields are missing\n* Review how product cards are structured. Position, labeling, and attribute density seem to influence AI agents more than most expect\n* Look at product descriptions from the POV of what AI models weigh by default (price, rating, reviews, badges). If these signals are faint or inconsistent, the agent has no basis to justify choosing the item\n\nThe gap between “agent visited” and “agent recommended something” seems to come down to how interpretable the markup is. The sandbox experiments made that pretty clear.\n\nAnyone else run similar tests or experimented with layout changes for AI?",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.91,
    "subreddit_type": "public",
    "ups": 24,
    "downs": 0,
    "created_utc": 1765373960.0,
    "media": null,
    "is_video": false,
    "num_comments": 23,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.770545629527841
  },
  {
    "score": 24,
    "title": "Custom Google Search Console tool using the API",
    "selftext": "Wondering if anyone has used the Google Search Console API to build any sort of useful tool or dashboard for themselves to review data that way. I know I can go in to GSC and click through all the data but I've been considering building a local app that pulls all the relevant info from GSC and then gives me tangible suggestions to make to my website based on the data. Has anyone tried something like this? I'd love to hear about others experiences before I do this myself.\n\n  \nThanks!",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.94,
    "subreddit_type": "public",
    "ups": 24,
    "downs": 0,
    "created_utc": 1764608396.0,
    "media": null,
    "is_video": false,
    "num_comments": 29,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.841500636031869
  },
  {
    "score": 25,
    "title": "FYI - Google Dropping support for 7 schema types",
    "selftext": "On the Google Developer Guide\n\n  \n[https://developers.google.com/search/blog/2025/11/update-on-our-efforts](https://developers.google.com/search/blog/2025/11/update-on-our-efforts)\n\n  \nThe following structured data types will no longer be supported in Google Search results and will be phased out over the coming weeks and months:\n\n* [Book Actions](https://developers.google.com/search/docs/appearance/structured-data/book)\n* [Course Info](https://developers.google.com/search/docs/appearance/structured-data/course-info)\n* [Claim Review](https://developers.google.com/search/docs/appearance/structured-data/factcheck)\n* [Estimated Salary](https://developers.google.com/search/docs/appearance/structured-data/estimated-salary)\n* [Learning Video](https://developers.google.com/search/docs/appearance/structured-data/learning-video)\n* [Special Announcement](https://developers.google.com/search/docs/appearance/structured-data/special-announcements)\n* [Vehicle Listing](https://developers.google.com/search/docs/appearance/structured-data/vehicle-listing)\n\n",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.97,
    "subreddit_type": "public",
    "ups": 25,
    "downs": 0,
    "created_utc": 1762526406.0,
    "media": null,
    "is_video": false,
    "num_comments": 18,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.7818501484472327
  },
  {
    "score": 24,
    "title": "How Do You Guys Audit a Website? I'm New and Super Confused",
    "selftext": "Hey everyone,\n\nI’m new to SEO and I’m honestly struggling with how to properly **audit a website**.\n\nRight now, all I do is run Screaming Frog and look at the technical errors it shows. But I feel like auditing is much more than just crawling a site.\n\nSo how do YOU perform a complete website audit?  \nWhat steps, tools, or frameworks do you follow?\n\nAny advice from experienced SEOs would really help.",
    "subreddit": "TechSEO",
    "upvote_ratio": 0.9,
    "subreddit_type": "public",
    "ups": 24,
    "downs": 0,
    "created_utc": 1763985655.0,
    "media": null,
    "is_video": false,
    "num_comments": 29,
    "num_reports": null,
    "over_18": false,
    "category": "",
    "category_confidence": null,
    "category_rationale": "",
    "composite_score": 2.8115006360318686
  }
]